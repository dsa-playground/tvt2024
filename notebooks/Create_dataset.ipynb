{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import os\n",
    "# import sys\n",
    "# sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ZZP.csv', sep=\";\")\n",
    "df['Datum'] = pd.to_datetime(df['Datum'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datum'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.DatetimeIndex(df['Datum'], freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['ZZP5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Check if the series is stationary\n",
    "result = adfuller(data)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plot_acf(data, lags=50)\n",
    "plot_pacf(data, lags=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an ARIMA model to your data\n",
    "# model = ARIMA(data, order=(5,2,5), freq='D')\n",
    "model = ARIMA(data, order=(1,2,5), freq='D')\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast future data points\n",
    "n_forecast = 100\n",
    "forecast = model_fit.forecast(steps=n_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_data = pd.concat([data, pd.Series(forecast)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add a line trace for the extended_data\n",
    "fig.add_trace(go.Scatter(x=extended_data.index, y=extended_data, mode='lines', name='extended_data'))\n",
    "\n",
    "# Set the title and labels\n",
    "fig.update_layout(title='Extended Data Timeseries', xaxis_title='Time', yaxis_title='Value')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stappenplan:\n",
    "# - Trendlijn bepalen\n",
    "# - delta trendlijn bepalen\n",
    "# - Normaaldistributie maken van delta trendlijn\n",
    "# - Meerjaren trendlijn maken\n",
    "# - Op basis van normaal distributie en meerjaren trendlijn voorspelling maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ZZP.csv', sep=\";\")\n",
    "df['Datum'] = pd.to_datetime(df['Datum'], format='%d-%m-%Y')\n",
    "df['ZZP_VVT'] = df['ZZP6'] + df['ZZP7'] + df['ZZP8'] + df['ZZP9'] + df['ZZP10']\n",
    "\n",
    "data = df['ZZP_VVT']\n",
    "\n",
    "time = np.arange(len(data))\n",
    "slope, intercept = np.polyfit(time, data, 1)\n",
    "\n",
    "extension_period = 365*3\n",
    "extended_time = np.arange(len(data) + extension_period)\n",
    "# Create a trend line\n",
    "trend = intercept + slope * extended_time\n",
    "df_extended = pd.DataFrame({'Datum': df['Datum'].iloc[0] + pd.to_timedelta(extended_time, unit='D'), 'trend': trend})\n",
    "\n",
    "df_extended = pd.concat([df['ZZP_VVT'], df_extended], axis=1)\n",
    "df_extended['delta'] = df_extended['ZZP_VVT'] - df_extended['trend']\n",
    "\n",
    "df_extended['synthetic_delta'] = np.random.normal(loc=0.0, scale=df_extended['delta'].std(), size=len(df_extended))\n",
    "df_extended['synthetic_ZZP_VVT_'] = df_extended['trend'] + df_extended['synthetic_delta']\n",
    "\n",
    "df_extended['synthetic_ZZP_VVT'] = df_extended['synthetic_ZZP_VVT_'].rolling(window=7).mean()\n",
    "df_extended = df_extended.dropna(subset=['synthetic_ZZP_VVT'])\n",
    "df_extended['synthetic_ZZP_VVT'] = df_extended['synthetic_ZZP_VVT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_clients = df_extended['synthetic_ZZP_VVT'].to_dict()\n",
    "dict_timeseries = {}\n",
    "dict_timeseries['ts_clients'] = ts_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the updated dictionary back to a JSON file\n",
    "with open('data/dict_timeseries.json', 'w') as f:\n",
    "    json.dump(dict_timeseries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from a JSON file\n",
    "with open('data/dict_timeseries.json', 'r') as f:\n",
    "    dict_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.to_csv('data/ZZP_extended.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZZP_VVT'] = df['ZZP6'] + df['ZZP7'] + df['ZZP8'] + df['ZZP9'] + df['ZZP10']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['ZZP_VVT']\n",
    "# Assuming 'data' is your time series\n",
    "time = np.arange(len(data))\n",
    "slope, intercept = np.polyfit(time, data, 1)\n",
    "\n",
    "extension_period = 365*3\n",
    "extended_time = np.arange(len(data) + extension_period)\n",
    "# Create a trend line\n",
    "trend = intercept + slope * extended_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_clients = data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the dictionary from ts.py\n",
    "from data.ts import dict_timeseries\n",
    "\n",
    "# Update the dictionary\n",
    "dict_timeseries['ts_clients'].update(ts_clients)\n",
    "\n",
    "# Write the updated dictionary back to ts.py\n",
    "with open('data/ts.py', 'a') as f:\n",
    "    f.write(f'\\dict_timeseries = {dict_timeseries}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Import the dictionary from ts.py\n",
    "from data.ts import dict_timeseries\n",
    "\n",
    "# Update the dictionary\n",
    "dict_timeseries['ts_clients'].update(ts_clients)\n",
    "\n",
    "# Write the updated dictionary back to a JSON file\n",
    "with open('data/dict_timeseries.json', 'w') as f:\n",
    "    json.dump(dict_timeseries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from a JSON file\n",
    "with open('data/dict_timeseries.json', 'r') as f:\n",
    "    dict_timeseries = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_timeseries['ts_purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = pd.DataFrame({'Datum': df['Datum'].iloc[0] + pd.to_timedelta(extended_time, unit='D'), 'trend': trend})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = pd.concat([df['ZZP_VVT'], df_extended], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended['delta'] = df_extended['ZZP_VVT'] - df_extended['trend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = pd.concat([df['ZZP_VVT'], df_extended], axis=1)\n",
    "df_extended['delta'] = df_extended['ZZP_VVT'] - df_extended['trend']\n",
    "\n",
    "df_extended['synthetic_delta'] = np.random.normal(loc=0.0, scale=df_extended['delta'].std(), size=len(df_extended))\n",
    "df_extended['synthetic_ZZP_VVT_'] = df_extended['trend'] + df_extended['synthetic_delta']\n",
    "\n",
    "df_extended['synthetic_ZZP_VVT'] = df_extended['synthetic_ZZP_VVT_'].rolling(window=7).mean()\n",
    "df_extended = df_extended.dropna(subset=['synthetic_ZZP_VVT'])\n",
    "df_extended['synthetic_ZZP_VVT'] = df_extended['synthetic_ZZP_VVT'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_extended['ZZP_VVT'], label='Original')\n",
    "plt.plot(df_extended['trend'], label='Trend', color='red')\n",
    "plt.plot(df_extended['synthetic_ZZP_VVT'], label='Trend', color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'data' is your time series\n",
    "time = np.arange(len(data))\n",
    "slope, intercept = np.polyfit(time, data, 1)\n",
    "\n",
    "# Create a trend line\n",
    "trend = intercept + slope * time\n",
    "\n",
    "# Plot the original time series and the trend\n",
    "plt.plot(data, label='Original')\n",
    "plt.plot(time, trend, label='Trend', color='red')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Moving average\n",
    "data_ma = data.rolling(window=12).mean()  # window size depends on the nature of the data\n",
    "\n",
    "# Plot the original time series and the moving average\n",
    "plt.plot(data, label='Original')\n",
    "plt.plot(data_ma, label='Moving Average', color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
